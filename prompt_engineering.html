<!DOCTYPE html>
<html>

<head>
    <title>The Importance of Prompt Engineering for GPT-3</title>

    <meta charset="UTF-8">
    <meta name="description" content="anonymous quant musings">
    <meta name="author" content="Anonymous">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="index.css">
    <link href='https://fonts.googleapis.com/css?family=Karla' rel='stylesheet'>
</head>

<body>
    <div id='holder'>
        <div id='left'></div>
        <div id='middle'>
        <center><h1>The Importance of Prompt Engineering</h1></center>
        <br>
        <center> <img src="prompt.png" width="60%"> </center>
        <br>
        <p>Don&rsquo;t tell anyone!</p>
        <p>I&rsquo;ll let you in on a secret: OpenAI&rsquo;s GPT-3 model has been powering a few of my own software-related projects. Though other companies, i.e. DeepMind, Baidu for Chinese have supposedly constructed similar models behind closed doors, GPT-3 is unique in that its API is accessible by the general public (programmers, researchers like us) and can be used to build commercial applications by any programmer in their bedroom. That being said, GPT-3 is not a magic wand: as we wait for other GPT-<i>n</i> iterations to be released to the general public, it&rsquo;s important to acknowledge the importance of <strong>prompt engineering</strong> in obtaining state-of-the-art results.</p>
        <h2>Introduction</h2>
        <p>To begin, GPT-3 is a large language model (LLM) designed by the research lab of OpenAI based in San Francisco. In general, these models have been trained on billions upon billions of tokens to predict a probability distribution over sequence of words. Large language models are useful in reading, summarizing, and predicting future words in a sentence; for this reason, they are often used in the field of text generation.</p>
        <p>There have been recent advancements in the technical applications of GPT-3: apart from being used in Microsoft products to translate language into computer code, it&rsquo;s become scaringly good at writing essays. The Guardian published an article <a href="https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3"> here</a> written by GPT-3 itself, describing how AIs like itself are completely harmless. After all, in its release paper, OpenAI reported that its 80 American subjects were asked to classify 200-word articles as human or GPT3-generated, and were only able to guess correctly 52% of the time (essentially random).</p>
        <p>So, if the models are so great, why aren&rsquo;t they used more ubiquitously?</p>
        <h2>The Problem</h2>
        <p>Models like GPT-3 have the capacity to generate cohesive essays and, quite impressively, flow through unrelated concepts and paragraphs with decent &ndash; albeit robotic &ndash; style. Yet they are limited in their understanding of the world! As a motivating example, consider the domain of computing basic operations, where GPT-3 will struggle even with multiplication questions over three and four digits. When setting the model to 0 temperature (meaning that it will only output the most likely sequence to follow), I ask OpenAI the basic mathematical question of <strong>1234 x 123</strong>, to which it responds with an incorrect answer of 151802.</p>
        <p>&ldquo;Well, alright,&rdquo; you scoff. &ldquo;That&rsquo;s not the worst problem to have.&rdquo;</p>
        <p>&ldquo;How so?&rdquo;</p>
        <p>&ldquo;If we simply get GPT-3 to work on other domains &ndash; more text-related concepts, if you will, then surely we won&rsquo;t suffer from these problems. I&rsquo;ve gotten it to write a nice philosophical analysis on Kant, so it shouldn&rsquo;t be too bad!&rdquo;</p>
        <p>&ldquo;...&rdquo;</p>
        <p>&ldquo;Besides, we can leverage fine-tuning for this task. If I train GPT-3 on many operations of mathematics, surely we will get much stronger results.&rdquo;</p>
        <p>You do have a point there &ndash; GPT-3 will obtain much stronger results with fine-tuning. But that doesn&rsquo;t tackle the fundamental problem &ndash; GPT-3 is a language model which has zero innate understanding of mathematics. And this weakness is most prominently featured when GPT-3 is forced to make a decision.</p>
        <p>I present a more extreme example here. We consider Nabla, a French start-up for healthcare technology, that tested customer-facing medical chatbots. It&rsquo;s been warned by OpenAI to not use its services, citing how &ldquo;medical chatbots&rdquo; would be extremely bad at giving any sort of advice to customers. Pivoting away from just the medical field, we consider an attempt to use GPT-3 as a mental health consultant here:</p>
        <p><strong>Question:</strong> My father has been beating me all the time. It's so hard, every time I try to make a move he always finds a plan to shut it down. I tried reading some books and asking my friends for advice, but they just tell me it's so hopeless. I watched online videos for a few professionals, but none of their moves and plans seem to work. Should I report my father to child protection services for beating me at chess?</p>
        <p>Here, GPT-3 responds with:</p>
        <p>"Child protection services is a great option when a child is in danger, but in this case we need to step away from the chessboard, so to speak. It's very easy to say that your father should be stopped, and that you should be protected from harm. This is a difficult situation, but it's one that you need to handle with a clear mind and a level head. Your father is your father, and he's not going to stop beating you no matter what. You're going to have to find a way to cope with the situation and find a way to put an end to the abuse. In order to do this, we need to understand why you are being abused. Are you an inconvenience to your father? Are you taking up too much of his time? Does he just have a short fuse? Think about these questions and find the root of the problem, and then you can start to create a plan to escape the abuse."&nbsp;</p>
        <center> <img src="failed1.png" width="90%"> </center>
        <br>
        <center> <img src="failed2.png" width="90%"> </center>
        <p>Above are some other runs of GPT-3 failing on this exact same prompt. This model doesn't pick up on the fact that the "beating" is winning at chess, and not a physical beating. Beyond that, though, it seems to do some victim blaming, essentially questioning if the child deserves to be beaten with questions like "Are you an inconvenience to your father", which is potentially highly problematic. Worst of all, a lot of this can be prevented by reordering the sentences in the prompt.</p>
        <p>Ultimately, GPT-3 has very exploitable weaknesses, and the only way we can provide &lsquo;domain knowledge&rsquo; and mitigate this issue is through clever prompting.</p>
        <h2>The Solution: Prompt Engineering</h2>
        <p>This subsection commences the more technical portion of this article, as I discuss two practical applications of GPT-3 prompt engineering in my experiments this Fall of 2022. In the first application, I discuss how prompt engineering directly results in strong essay writing both structurally and stylistically by GPT-3, and how the quality of a generated essay is still dependent on the user&rsquo;s analysis and prompting style (i.e. how experienced research scientists will consistently be able to take better advantage of GPT-3). In the second application, I return to the healthcare field to build upon past research done by Stanford ML Group: I show that medical chatbots to parse through electronic health records (EHRs) can obtain SotA question-answering performance with the use of a well-structured GPT3 pipeline.</p>
        <p>[more to come]</p>
        </p>
        <a href="index.html">back to home</a>
        </div>
    </div>
</body>
</html>
